{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=2c432fc64bc742b1aabc0eb0d737a126\n",
      "ClearML results page: https://app.clear.ml/projects/f5e21c80429b490ea4443d4f94353224/experiments/2c432fc64bc742b1aabc0eb0d737a126/output/log\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(project_name=\"PCOS Diagnosis\", task_name= \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = task.get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import chi2,f_classif, mutual_info_classif, SelectKBest\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from yellowbrick.model_selection import CVScores\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCOS (Y/N)</th>\n",
       "      <th>Age (yrs)</th>\n",
       "      <th>Weight (Kg)</th>\n",
       "      <th>Height(Cm)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Group</th>\n",
       "      <th>Pulse rate(bpm)</th>\n",
       "      <th>RR (breaths/min)</th>\n",
       "      <th>Hb(g/dl)</th>\n",
       "      <th>Cycle(R/I)</th>\n",
       "      <th>...</th>\n",
       "      <th>Pimples(Y/N)</th>\n",
       "      <th>Fast food (Y/N)</th>\n",
       "      <th>Reg.Exercise(Y/N)</th>\n",
       "      <th>BP _Systolic (mmHg)</th>\n",
       "      <th>BP _Diastolic (mmHg)</th>\n",
       "      <th>Follicle No. (L)</th>\n",
       "      <th>Follicle No. (R)</th>\n",
       "      <th>Avg. F size (L) (mm)</th>\n",
       "      <th>Avg. F size (R) (mm)</th>\n",
       "      <th>Endometrium (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>44.6</td>\n",
       "      <td>152.0</td>\n",
       "      <td>19.30</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>10.48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>65.0</td>\n",
       "      <td>161.5</td>\n",
       "      <td>24.92</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>68.8</td>\n",
       "      <td>165.0</td>\n",
       "      <td>25.27</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>11.80</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>65.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>29.67</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>52.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>20.06</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>74.1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>27.22</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>64.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>26.30</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>10.90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>58.5</td>\n",
       "      <td>159.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>40.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>16.02</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>11.80</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>52.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>23.11</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>71.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>26.72</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>49.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>19.14</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PCOS (Y/N)  Age (yrs)  Weight (Kg)  Height(Cm)    BMI  Blood Group  \\\n",
       "0            0         28         44.6       152.0  19.30           15   \n",
       "1            0         36         65.0       161.5  24.92           15   \n",
       "2            1         33         68.8       165.0  25.27           11   \n",
       "3            0         37         65.0       148.0  29.67           13   \n",
       "4            0         25         52.0       161.0  20.06           11   \n",
       "5            0         36         74.1       165.0  27.22           15   \n",
       "6            0         34         64.0       156.0  26.30           11   \n",
       "7            0         33         58.5       159.0  23.14           13   \n",
       "8            0         32         40.0       158.0  16.02           11   \n",
       "9            0         36         52.0       150.0  23.11           15   \n",
       "10           0         20         71.0       163.0  26.72           15   \n",
       "11           0         26         49.0       160.0  19.14           13   \n",
       "\n",
       "    Pulse rate(bpm)  RR (breaths/min)  Hb(g/dl)  Cycle(R/I)  ...  \\\n",
       "0                78                22     10.48           0  ...   \n",
       "1                74                20     11.70           0  ...   \n",
       "2                72                18     11.80           0  ...   \n",
       "3                72                20     12.00           0  ...   \n",
       "4                72                18     10.00           0  ...   \n",
       "5                78                28     11.20           0  ...   \n",
       "6                72                18     10.90           0  ...   \n",
       "7                72                20     11.00           0  ...   \n",
       "8                72                18     11.80           0  ...   \n",
       "9                80                20     10.00           1  ...   \n",
       "10               80                20     10.00           0  ...   \n",
       "11               72                20      9.50           0  ...   \n",
       "\n",
       "    Pimples(Y/N)  Fast food (Y/N)  Reg.Exercise(Y/N)  BP _Systolic (mmHg)  \\\n",
       "0              0              1.0                  0                  110   \n",
       "1              0              0.0                  0                  120   \n",
       "2              1              1.0                  0                  120   \n",
       "3              0              0.0                  0                  120   \n",
       "4              0              0.0                  0                  120   \n",
       "5              0              0.0                  0                  110   \n",
       "6              0              0.0                  0                  120   \n",
       "7              0              0.0                  0                  120   \n",
       "8              0              0.0                  0                  120   \n",
       "9              0              0.0                  0                  110   \n",
       "10             0              0.0                  0                  110   \n",
       "11             0              0.0                  0                  120   \n",
       "\n",
       "    BP _Diastolic (mmHg)  Follicle No. (L)  Follicle No. (R)  \\\n",
       "0                     80                 3                 3   \n",
       "1                     70                 3                 5   \n",
       "2                     80                13                15   \n",
       "3                     70                 2                 2   \n",
       "4                     80                 3                 4   \n",
       "5                     70                 9                 6   \n",
       "6                     80                 6                 6   \n",
       "7                     80                 7                 6   \n",
       "8                     80                 5                 7   \n",
       "9                     80                 1                 1   \n",
       "10                    80                 7                15   \n",
       "11                    80                 4                 2   \n",
       "\n",
       "    Avg. F size (L) (mm)  Avg. F size (R) (mm)  Endometrium (mm)  \n",
       "0                   18.0                  18.0               8.5  \n",
       "1                   15.0                  14.0               3.7  \n",
       "2                   18.0                  20.0              10.0  \n",
       "3                   15.0                  14.0               7.5  \n",
       "4                   16.0                  14.0               7.0  \n",
       "5                   16.0                  20.0               8.0  \n",
       "6                   15.0                  16.0               6.8  \n",
       "7                   15.0                  18.0               7.1  \n",
       "8                   17.0                  17.0               4.2  \n",
       "9                   14.0                  17.0               2.5  \n",
       "10                  17.0                  20.0               6.0  \n",
       "11                  18.0                  19.0               7.8  \n",
       "\n",
       "[12 rows x 42 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../datasets/PCOS_clean_data_without_infertility.csv')\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 538 entries, 0 to 537\n",
      "Data columns (total 42 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   PCOS (Y/N)              538 non-null    int64  \n",
      " 1   Age (yrs)               538 non-null    int64  \n",
      " 2   Weight (Kg)             538 non-null    float64\n",
      " 3   Height(Cm)              538 non-null    float64\n",
      " 4   BMI                     538 non-null    float64\n",
      " 5   Blood Group             538 non-null    int64  \n",
      " 6   Pulse rate(bpm)         538 non-null    int64  \n",
      " 7   RR (breaths/min)        538 non-null    int64  \n",
      " 8   Hb(g/dl)                538 non-null    float64\n",
      " 9   Cycle(R/I)              538 non-null    int64  \n",
      " 10  Cycle length(days)      538 non-null    int64  \n",
      " 11  Marraige Status (Yrs)   538 non-null    float64\n",
      " 12  Pregnant(Y/N)           538 non-null    int64  \n",
      " 13  No. of aborptions       538 non-null    int64  \n",
      " 14  I   beta-HCG(mIU/mL)    538 non-null    float64\n",
      " 15  II    beta-HCG(mIU/mL)  538 non-null    float64\n",
      " 16  FSH(mIU/mL)             538 non-null    float64\n",
      " 17  LH(mIU/mL)              538 non-null    float64\n",
      " 18  FSH/LH                  538 non-null    float64\n",
      " 19  Hip(inch)               538 non-null    int64  \n",
      " 20  Waist(inch)             538 non-null    int64  \n",
      " 21  Waist:Hip Ratio         538 non-null    float64\n",
      " 22  TSH (mIU/L)             538 non-null    float64\n",
      " 23  AMH(ng/mL)              538 non-null    float64\n",
      " 24  PRL(ng/mL)              538 non-null    float64\n",
      " 25  Vit D3 (ng/mL)          538 non-null    float64\n",
      " 26  PRG(ng/mL)              538 non-null    float64\n",
      " 27  RBS(mg/dl)              538 non-null    float64\n",
      " 28  Weight gain(Y/N)        538 non-null    int64  \n",
      " 29  hair growth(Y/N)        538 non-null    int64  \n",
      " 30  Skin darkening (Y/N)    538 non-null    int64  \n",
      " 31  Hair loss(Y/N)          538 non-null    int64  \n",
      " 32  Pimples(Y/N)            538 non-null    int64  \n",
      " 33  Fast food (Y/N)         538 non-null    float64\n",
      " 34  Reg.Exercise(Y/N)       538 non-null    int64  \n",
      " 35  BP _Systolic (mmHg)     538 non-null    int64  \n",
      " 36  BP _Diastolic (mmHg)    538 non-null    int64  \n",
      " 37  Follicle No. (L)        538 non-null    int64  \n",
      " 38  Follicle No. (R)        538 non-null    int64  \n",
      " 39  Avg. F size (L) (mm)    538 non-null    float64\n",
      " 40  Avg. F size (R) (mm)    538 non-null    float64\n",
      " 41  Endometrium (mm)        538 non-null    float64\n",
      "dtypes: float64(21), int64(21)\n",
      "memory usage: 176.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.report_table(\"PCOS Cleaned Dataset\", \"Original\", iteration=0, table_plot=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"PCOS (Y/N)\",\n",
    "            \"Blood Group\",\n",
    "            \"Height(Cm)\",\n",
    "            \"Pregnant(Y/N)\",\n",
    "             \"PRG(ng/mL)\",\n",
    "            \"RR (breaths/min)\",\n",
    "            \"No. of aborptions\",\n",
    "            \"FSH/LH\",\n",
    "            \"I   beta-HCG(mIU/mL)\",\n",
    "            \"II    beta-HCG(mIU/mL)\",\n",
    "            \"TSH (mIU/L)\",\n",
    "            \"FSH(mIU/mL)\",\n",
    "            \"LH(mIU/mL)\",\n",
    "            \"Waist:Hip Ratio\",\n",
    "            \"PRL(ng/mL)\",\n",
    "            \"BP _Diastolic (mmHg)\",\n",
    "            \"BP _Systolic (mmHg)\",\n",
    "            \"Reg.Exercise(Y/N)\",\n",
    "            \"RBS(mg/dl)\"\n",
    "            ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"PCOS (Y/N)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling on Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "resample = SMOTEENN(sampling_strategy=\"auto\", random_state =0)\n",
    "X, y = resample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.report_table(\"PCOS Cleaned Dataset - X\", \"Over-Under Sampled\", iteration=0, table_plot=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.report_table(\"PCOS Cleaned Dataset - y\", \"Over-Under Sampled\", iteration=0, table_plot=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.15, random_state=0, stratify= y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 23)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 23)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 23)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "X_dev = scaler.transform(X_dev)\n",
    "X_dev = pd.DataFrame(X_dev)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "\n",
    "# Setting Column Names from dataset\n",
    "X_train.columns = X.columns\n",
    "X_test.columns = X.columns\n",
    "X_dev.columns = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.to_numpy().reshape(y_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = y_test.to_numpy().reshape(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = X_dev.to_numpy().reshape(X_dev.shape[0], X_dev.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_dev = y_dev.to_numpy().reshape(y_dev.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "y_dev = to_categorical(y_dev, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'optimizer': \"Adam\",\n",
    "    'epochs': 200,\n",
    "    'early_stopping_paitence':50,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'metric': ['AUC','accuracy', 'Precision', 'Recall']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report to ClearML\n",
    "parameters = task.connect(parameters, name=\"Hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(128, (3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(layers.Conv1D(64, (3), activation='relu'))\n",
    "model.add(layers.Conv1D(32, (3), activation='relu'))\n",
    "model.add(layers.Conv1D(64, (3), activation='relu'))\n",
    "model.add(layers.Conv1D(64, (5), activation='relu'))\n",
    "model.add(layers.Conv1D(32, (5), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=parameters['early_stopping_paitence'], monitor='val_loss', mode='min'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=parameters['optimizer'],\n",
    "              loss=parameters['loss'],\n",
    "              metrics=parameters['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 21, 128)           512       \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 19, 64)            24640     \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 17, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 15, 64)            6208      \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 11, 64)            20544     \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 7, 32)             10272     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 224)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               28800     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,122\n",
      "Trainable params: 125,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.1980 - auc: 0.9828 - accuracy: 0.9415 - precision: 0.9415 - recall: 0.9415 - val_loss: 0.1762 - val_auc: 0.9834 - val_accuracy: 0.9310 - val_precision: 0.9153 - val_recall: 0.9310\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.2256 - auc: 0.9684 - accuracy: 0.9231 - precision: 0.9174 - recall: 0.9231 - val_loss: 0.2322 - val_auc: 0.9741 - val_accuracy: 0.8966 - val_precision: 0.8966 - val_recall: 0.8966\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1897 - auc: 0.9772 - accuracy: 0.9200 - precision: 0.9202 - recall: 0.9231 - val_loss: 0.1693 - val_auc: 0.9838 - val_accuracy: 0.8966 - val_precision: 0.8983 - val_recall: 0.9138\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1389 - auc: 0.9866 - accuracy: 0.9508 - precision: 0.9421 - recall: 0.9508 - val_loss: 0.1817 - val_auc: 0.9851 - val_accuracy: 0.8966 - val_precision: 0.8966 - val_recall: 0.8966\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1542 - auc: 0.9853 - accuracy: 0.9508 - precision: 0.9508 - recall: 0.9508 - val_loss: 0.1381 - val_auc: 0.9935 - val_accuracy: 0.9655 - val_precision: 0.9661 - val_recall: 0.9828\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1140 - auc: 0.9904 - accuracy: 0.9662 - precision: 0.9662 - recall: 0.9662 - val_loss: 0.1039 - val_auc: 0.9912 - val_accuracy: 0.9138 - val_precision: 0.9153 - val_recall: 0.9310\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1436 - auc: 0.9856 - accuracy: 0.9569 - precision: 0.9511 - recall: 0.9569 - val_loss: 0.1398 - val_auc: 0.9875 - val_accuracy: 0.9310 - val_precision: 0.9322 - val_recall: 0.9483\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1228 - auc: 0.9887 - accuracy: 0.9631 - precision: 0.9631 - recall: 0.9631 - val_loss: 0.1058 - val_auc: 0.9932 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1110 - auc: 0.9922 - accuracy: 0.9631 - precision: 0.9631 - recall: 0.9631 - val_loss: 0.0780 - val_auc: 0.9976 - val_accuracy: 0.9655 - val_precision: 0.9655 - val_recall: 0.9655\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0989 - auc: 0.9934 - accuracy: 0.9631 - precision: 0.9602 - recall: 0.9662 - val_loss: 0.1579 - val_auc: 0.9891 - val_accuracy: 0.9310 - val_precision: 0.9474 - val_recall: 0.9310\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.1720 - auc: 0.9816 - accuracy: 0.9446 - precision: 0.9446 - recall: 0.9446 - val_loss: 0.3182 - val_auc: 0.9487 - val_accuracy: 0.8793 - val_precision: 0.8793 - val_recall: 0.8793\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1830 - auc: 0.9831 - accuracy: 0.9262 - precision: 0.9262 - recall: 0.9262 - val_loss: 0.1142 - val_auc: 0.9926 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1486 - auc: 0.9873 - accuracy: 0.9508 - precision: 0.9506 - recall: 0.9477 - val_loss: 0.2352 - val_auc: 0.9703 - val_accuracy: 0.8793 - val_precision: 0.8793 - val_recall: 0.8793\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1305 - auc: 0.9879 - accuracy: 0.9631 - precision: 0.9631 - recall: 0.9631 - val_loss: 0.1593 - val_auc: 0.9887 - val_accuracy: 0.9310 - val_precision: 0.9310 - val_recall: 0.9310\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.1041 - auc: 0.9925 - accuracy: 0.9631 - precision: 0.9631 - recall: 0.9631 - val_loss: 0.1229 - val_auc: 0.9902 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0860 - auc: 0.9943 - accuracy: 0.9692 - precision: 0.9692 - recall: 0.9692 - val_loss: 0.1352 - val_auc: 0.9933 - val_accuracy: 0.9310 - val_precision: 0.9310 - val_recall: 0.9310\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0878 - auc: 0.9945 - accuracy: 0.9754 - precision: 0.9784 - recall: 0.9754 - val_loss: 0.1760 - val_auc: 0.9842 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0872 - auc: 0.9948 - accuracy: 0.9692 - precision: 0.9692 - recall: 0.9692 - val_loss: 0.1282 - val_auc: 0.9914 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0686 - auc: 0.9964 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - val_loss: 0.1160 - val_auc: 0.9944 - val_accuracy: 0.9655 - val_precision: 0.9655 - val_recall: 0.9655\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0536 - auc: 0.9976 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - val_loss: 0.0780 - val_auc: 0.9961 - val_accuracy: 0.9483 - val_precision: 0.9649 - val_recall: 0.9483\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0811 - auc: 0.9956 - accuracy: 0.9723 - precision: 0.9723 - recall: 0.9723 - val_loss: 0.1441 - val_auc: 0.9900 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0757 - auc: 0.9957 - accuracy: 0.9785 - precision: 0.9784 - recall: 0.9754 - val_loss: 0.1030 - val_auc: 0.9957 - val_accuracy: 0.9655 - val_precision: 0.9655 - val_recall: 0.9655\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0827 - auc: 0.9942 - accuracy: 0.9754 - precision: 0.9753 - recall: 0.9723 - val_loss: 0.0851 - val_auc: 0.9955 - val_accuracy: 0.9828 - val_precision: 0.9828 - val_recall: 0.9828\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0685 - auc: 0.9958 - accuracy: 0.9846 - precision: 0.9816 - recall: 0.9846 - val_loss: 0.1629 - val_auc: 0.9912 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0576 - auc: 0.9976 - accuracy: 0.9815 - precision: 0.9816 - recall: 0.9846 - val_loss: 0.1175 - val_auc: 0.9938 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0516 - auc: 0.9981 - accuracy: 0.9846 - precision: 0.9847 - recall: 0.9877 - val_loss: 0.1687 - val_auc: 0.9902 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0491 - auc: 0.9988 - accuracy: 0.9815 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.2130 - val_auc: 0.9758 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0406 - auc: 0.9991 - accuracy: 0.9846 - precision: 0.9847 - recall: 0.9877 - val_loss: 0.2085 - val_auc: 0.9872 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0359 - auc: 0.9993 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - val_loss: 0.2197 - val_auc: 0.9854 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0451 - auc: 0.9989 - accuracy: 0.9785 - precision: 0.9785 - recall: 0.9785 - val_loss: 0.1478 - val_auc: 0.9831 - val_accuracy: 0.9655 - val_precision: 0.9655 - val_recall: 0.9655\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0320 - auc: 0.9993 - accuracy: 0.9877 - precision: 0.9907 - recall: 0.9877 - val_loss: 0.1339 - val_auc: 0.9915 - val_accuracy: 0.9655 - val_precision: 0.9655 - val_recall: 0.9655\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0758 - auc: 0.9967 - accuracy: 0.9723 - precision: 0.9722 - recall: 0.9692 - val_loss: 0.1292 - val_auc: 0.9911 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0514 - auc: 0.9987 - accuracy: 0.9815 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.1315 - val_auc: 0.9921 - val_accuracy: 0.9483 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0379 - auc: 0.9989 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - val_loss: 0.1294 - val_auc: 0.9926 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0288 - auc: 0.9996 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - val_loss: 0.2847 - val_auc: 0.9692 - val_accuracy: 0.9310 - val_precision: 0.9310 - val_recall: 0.9310\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0584 - auc: 0.9977 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - val_loss: 0.1603 - val_auc: 0.9908 - val_accuracy: 0.9310 - val_precision: 0.9310 - val_recall: 0.9310\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0267 - auc: 0.9995 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.1809 - val_auc: 0.9884 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0275 - auc: 0.9997 - accuracy: 0.9877 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.1679 - val_auc: 0.9911 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0147 - auc: 0.9999 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.1781 - val_auc: 0.9914 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0123 - auc: 0.9999 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.1648 - val_auc: 0.9917 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0093 - auc: 1.0000 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.2166 - val_auc: 0.9889 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0078 - auc: 1.0000 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.2645 - val_auc: 0.9795 - val_accuracy: 0.8966 - val_precision: 0.8966 - val_recall: 0.8966\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0059 - auc: 1.0000 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.3048 - val_auc: 0.9643 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0024 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3563 - val_auc: 0.9548 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0010 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3722 - val_auc: 0.9672 - val_accuracy: 0.9310 - val_precision: 0.9310 - val_recall: 0.9310\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 5.9747e-04 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3681 - val_auc: 0.9588 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.8391e-04 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3760 - val_auc: 0.9511 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8279e-04 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3848 - val_auc: 0.9587 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.4078e-04 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3867 - val_auc: 0.9511 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.6992e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3956 - val_auc: 0.9435 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.0010e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4152 - val_auc: 0.9440 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.5550e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4326 - val_auc: 0.9440 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.4297e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4481 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.8300e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4586 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2516e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4703 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8407e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4785 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5531e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4854 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.3667e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4919 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.2603e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5006 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.1007e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5067 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.0067e-05 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5121 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.2751e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5174 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.4604e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5221 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.8352e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5265 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 7.3067e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5316 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 6.6606e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5377 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.1065e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5415 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.6757e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5446 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.3575e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5478 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.9550e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5508 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 4.6876e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5532 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.4563e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5561 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.2674e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5600 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.9733e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5623 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.7790e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5648 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.6070e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5682 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.4289e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5714 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.2316e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5738 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.1039e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5775 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.8845e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5801 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.7319e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5866 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.4825e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5903 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.3258e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5932 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1924e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5956 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.0604e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5990 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.9262e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6025 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.8176e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6059 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7046e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6091 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.6244e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6130 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5215e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6164 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.4388e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6202 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.3468e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6239 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.2414e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6280 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.1785e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6328 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.0988e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6366 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0416e-06 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6405 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 9.7951e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6438 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.4250e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6482 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 8.7638e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6520 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.3175e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6556 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.9180e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6594 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 7.5318e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6627 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.1874e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6662 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.8464e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6697 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.5613e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6732 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 6.2929e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6768 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5.9873e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6791 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.7627e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6825 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.5524e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6861 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.2883e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6891 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.0982e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6918 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4.9047e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6947 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.7339e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6978 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.5470e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7005 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 4.4025e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7029 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.2303e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7052 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.1163e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7082 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.9693e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7110 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.8224e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7138 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.6181e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7167 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.4649e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7215 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.3624e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7249 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.2398e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7273 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 3.1601e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7298 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 3.0500e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7319 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.9714e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7344 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.8856e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7362 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.8035e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7381 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.7329e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7403 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.6620e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7426 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.5804e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7443 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.5241e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7465 - val_auc: 0.9444 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.4614e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7485 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.3995e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7534 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.3118e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7561 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.2375e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7578 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.1906e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7595 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.1391e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7615 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.0918e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7632 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.0407e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7648 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.0002e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7666 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.9561e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7681 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.9170e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7698 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.8774e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7714 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8360e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7729 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.8016e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7745 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7669e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7759 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7304e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7777 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.6948e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7790 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.6636e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7804 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.6308e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7820 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6016e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7833 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.5643e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7848 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.5378e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7867 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.4767e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7880 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.4530e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7895 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.4205e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7910 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.3924e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7942 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.3594e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7959 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.3326e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7975 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.2993e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7989 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.2627e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8002 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.2413e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8015 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.2150e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8028 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 1.1974e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8041 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 1.1787e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8055 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.1570e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8066 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.1416e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8079 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.1240e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8091 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.1053e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8101 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.0881e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8113 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 1.0678e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8125 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.0398e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8152 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 1.0265e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8171 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 1.0039e-07 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8181 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 9.8585e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8191 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 9.7138e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8202 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 9.5785e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8212 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 9.4245e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8222 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 9.3156e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8234 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 9.1776e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8244 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.0610e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8253 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 8.9343e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8264 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 8.8070e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8275 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 8.6944e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8283 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 8.5600e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8292 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 8.4439e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8301 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 8.3420e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8313 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 8.2224e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8322 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 8.1038e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8332 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 8.0019e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8352 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 7.8791e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8365 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 7.7734e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8374 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 7.6958e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8384 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.5553e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8394 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 7.4586e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8402 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 7.3784e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8412 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 7.2756e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8420 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 7.1925e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8429 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 7.0860e-08 - auc: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8438 - val_auc: 0.9449 - val_accuracy: 0.9138 - val_precision: 0.9138 - val_recall: 0.9138\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "epochs=parameters['epochs'],\n",
    "validation_data= (X_dev,y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.title(\"Learning curve (Accuracy)\")\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Scores')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show() # Necessary to track plot with ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.title(\"Learning curve (Loss)\")\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show() # Necessary to track plot with ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 4ms/step - loss: 1.7490 - auc: 0.9367 - accuracy: 0.9271 - precision: 0.9271 - recall: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7489938735961914,\n",
       " 0.9367404580116272,\n",
       " 0.9270833134651184,\n",
       " 0.9270833134651184,\n",
       " 0.9270833134651184]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close ClearML Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
